{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\esneider guzman\\desktop\\prueba\\.venv\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\esneider guzman\\desktop\\prueba\\.venv\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2\n",
    "%pip install python-dotenv\n",
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from dotenv import load_dotenv \n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY_GOOGLE= os.getenv(\"API_KEY_GOOGLE_GEMINI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We read and adjust to obtain the pdf and then they are transformed into .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_folder = './Docs/origin/'\n",
    "try:\n",
    "    pdf_files = [os.path.join(document_folder, f) for f in os.listdir(document_folder) if f.endswith('.pdf')]\n",
    "    txt_files = [os.path.join(document_folder, f) for f in os.listdir(document_folder) if f.endswith('.txt')]\n",
    "    documents_files = pdf_files + txt_files\n",
    "except:\n",
    "    raise ValueError(\"files don't found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF file: ./Docs/origin/1.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content (first 50 characters):\n",
      "Site Reliability Engineering at Google Taken from:\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as pdf_file:\n",
    "            reader = PyPDF2.PdfReader(pdf_file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "        \n",
    "       # Clean and process the text to remove unnecessary line breaks\n",
    "        text = \" \".join(text.splitlines())  # Combine the lines into a single paragraph\n",
    "        text = \" \".join(text.split())      # Remove multiple spaces\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "for file_path in documents_files:\n",
    "    if file_path.endswith('.pdf'):\n",
    "        print(f\"Processing PDF file: {file_path}\")\n",
    "        extracted_text = extract_text_from_pdf(file_path)\n",
    "        print(f\"Extracted content (first 50 characters):\\n{extracted_text[:50]}\")\n",
    "    elif file_path.endswith('.txt'):\n",
    "        print(f\"TXT file found: {file_path}\")\n",
    "        # Read the contents of the TXT file\n",
    "        with open(file_path, 'r', encoding='utf-8') as txt_file:\n",
    "            text = txt_file.read() \n",
    "        print(f\"Extracted content (first 50 characters)::\\n{text[:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text saved in: ./Docs/extracted\\1.txt\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"./Docs/extracted\"\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "for file_path in documents_files:\n",
    "    extracted_text = extract_text_from_pdf(file_path)\n",
    "    output_file = os.path.join(input_folder, os.path.basename(file_path).replace('.pdf', '.txt'))\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(extracted_text)\n",
    "    print(f\"Text saved in: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1.txt\n",
      "Generation saved in: ./Docs/pre-processing\\1.txt\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=API_KEY_GOOGLE)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "output_folder = \"./Docs/pre-processing\"  # Carpeta para guardar resultados\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def process_txt_file(file_path):\n",
    "    try:\n",
    "        # Leer el contenido del archivo .txt\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            raw_text = f.read()\n",
    "\n",
    "        # Prompt para estructurar el contenido\n",
    "        prompt = (\n",
    "            \"Organize and improve the following text into structured sections: \"\n",
    "            \"Introduction, Development, and Conclusion. Ensure it is clean, \"\n",
    "            \"detailed, and suitable for educational purposes:\\n\\n\"\n",
    "            f\"{raw_text}\"\n",
    "        )\n",
    "\n",
    "      \n",
    "        response = model.generate_content([prompt])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Procesar cada archivo .txt en la carpeta de entrada\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.txt'):\n",
    "        input_path = os.path.join(input_folder, file_name)\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        print(f\"Processing: {file_name}\")\n",
    "        processed_text = process_txt_file(input_path)\n",
    "\n",
    "        # Save the result if there are no errors\n",
    "        if processed_text:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(processed_text)\n",
    "            print(f\"Generation saved in: {output_path}\")\n",
    "        else:\n",
    "            print(f\"The file could not be processed: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating educational transcript for: 1.txt\n",
      "Transcript saved in: ./Docs/educational_transcript_1\\1.txt\n"
     ]
    }
   ],
   "source": [
    "output_folder_1 = \"./Docs/educational_transcript_1\"  # Carpeta para guardar transcripciones\n",
    "os.makedirs(output_folder_1, exist_ok=True)\n",
    "\n",
    "# Class duration (options: '30' or '60' minutes)\n",
    "lecture_duration = \"60\" # Change to \"60\" if a longer class is desired\n",
    "\n",
    "# Function to generate the educational transcript\n",
    "def create_educational_transcription(file_path):\n",
    "    try:\n",
    "       # Read the contents of the preprocessed file# Read the contents of the preprocessed file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            preprocessed_text = f.read()\n",
    "\n",
    "        # Prompt to generate educational transcript\n",
    "        prompt = (\n",
    "            f\"Using the following text, create a detailed and structured transcript suitable for a \"\n",
    "            f\"{lecture_duration}-minute lecture. The output should include: \\n\"\n",
    "            \"1. An introduction to the topic.\\n\"\n",
    "            \"2. A detailed explanation of key points, with examples.\\n\"\n",
    "            \"3. A conclusion with reflections or actionable steps for students.\\n\\n\"\n",
    "            \"Additionally, add a section at the end titled 'Activities' with tasks or questions \"\n",
    "            \"to engage students and reinforce their understanding of the topic.\\n\\n\"\n",
    "            f\"Input Text:\\n{preprocessed_text}\"\n",
    "        )\n",
    "\n",
    "        # Generar contenido con el modelo\n",
    "        response = model.generate_content([prompt])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Procesar cada archivo preprocesado en la carpeta de entrada\n",
    "for file_name in os.listdir(output_folder):\n",
    "    if file_name.endswith('.txt'):\n",
    "        input_path = os.path.join(output_folder, file_name)\n",
    "        output_path = os.path.join(output_folder_1, file_name)\n",
    "\n",
    "        print(f\"Generating educational transcript for: {file_name}\")\n",
    "        educational_transcription = create_educational_transcription(input_path)\n",
    "\n",
    "       \n",
    "        if educational_transcription:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(educational_transcription)\n",
    "            print(f\"Transcript saved in: {output_path}\")\n",
    "        else:\n",
    "            print(f\"The transcript could not be generated for: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating educational transcript for: 1.txt (30-minute lecture)\n",
      "Transcript saved to: ./Docs/educational_transcript_2\\1.txt\n"
     ]
    }
   ],
   "source": [
    "# Setting the duration (choose between \"30\" or \"60\")\n",
    "duration = \"30\"  # Change to \"60\" for a 60 minute class\n",
    "output_folder_2 = \"./Docs/educational_transcript_2\"  # Carpeta para guardar transcripciones\n",
    "os.makedirs(output_folder_2, exist_ok=True)\n",
    "\n",
    "\n",
    "base_prompt = {\n",
    "    \"30\": (\n",
    "        \"Using the following text, create a detailed and structured transcript suitable for a 30-minute lecture. \"\n",
    "        \"The output must include:\\n\"\n",
    "        \"1. An engaging introduction to the topic.\\n\"\n",
    "        \"2. Detailed explanations of key points, supported by examples.\\n\"\n",
    "        \"3. A conclusion with reflections and actionable next steps for students.\\n\"\n",
    "        \"4. Activities for students, such as questions, practical exercises, or case studies.\\n\\n\"\n",
    "        \"Text:\\n{content}\"\n",
    "    ),\n",
    "    \"60\": (\n",
    "        \"Using the following text, create a detailed and structured transcript suitable for a 60-minute lecture. \"\n",
    "        \"The output must include:\\n\"\n",
    "        \"1. An engaging and comprehensive introduction to the topic.\\n\"\n",
    "        \"2. Thorough explanations of key points, supported by detailed examples and case studies.\\n\"\n",
    "        \"3. A conclusion with reflections, future learning paths, and actionable next steps for students.\\n\"\n",
    "        \"4. Activities for students, including in-depth questions, group exercises, or real-world case studies.\\n\\n\"\n",
    "        \"Text:\\n{content}\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def create_educational_transcription(file_path, duration):\n",
    "    try:\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            preprocessed_text = f.read()\n",
    "\n",
    "        prompt = base_prompt[duration].format(content=preprocessed_text)\n",
    "\n",
    "        response = model.generate_content([prompt])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "for file_name in os.listdir(output_folder):\n",
    "    if file_name.endswith('.txt'):\n",
    "        input_path = os.path.join(output_folder, file_name)\n",
    "        output_path = os.path.join(output_folder_2, file_name)\n",
    "\n",
    "        print(\n",
    "            f\"Generating educational transcript for: {file_name} ({duration}-minute lecture)\")\n",
    "        educational_transcription = create_educational_transcription(\n",
    "            input_path, duration)\n",
    "\n",
    "        if educational_transcription:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(educational_transcription)\n",
    "            print(f\"Transcript saved to: {output_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to generate transcript for: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
